  "from re import VERBOSE\n",
        "#Step 1 : importing libraries\n",
        "import  tensorflow as tf\n",
        "from tensorflow.keras import datasets , layers ,models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Step 2: Loading and pre-processing the CIDAR-10 Dataset.\n",
        "(train_images, train_labels),(test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "#Step 3 : Normalising pixel values to be between 0 and 1.\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "#Step 4 : Defining the class names for CIFAR-10 images\n",
        "class_name = ['airplane', 'automobile' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck']\n",
        "\n",
        "#Step 5 :  (Machine learning part) Visualising a few training images from CIFAR-10 dataset.\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i],cmap = plt.cm.binary)\n",
        "  plt.xlabel(class_name[train_labels[i][0]])\n",
        "plt.show()\n",
        "\n",
        "#Step 6 : Building th CNN Model(customised model).\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32,(3,3), activation = 'relu', input_shape =(32,32,3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64,(3,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64,(3,3), activation = 'relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "#Step 7 : Printing the model summary.\n",
        "model.summary()\n",
        "\n",
        "#step 8 : Compiling the CNN Model.\n",
        "model.compile(optimizer = 'adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics = ['accuracy'] )\n",
        "\n",
        "#step 9 : Training the CNN Model.\n",
        "history = model.fit(train_images, train_labels, epochs=10,validation_data=(test_images,test_labels))\n",
        "\n",
        "#Step 10 : Evaluating the performance of CNN model.\n",
        "test_loss, test_acc= model.evaluate(test_images,test_labels,verbose =2)\n",
        "print(f'\\n test Accuracy is : {test_acc}')\n",
        "\n",
        "#Step 11 : plotting the training and validation accuracy and loss values\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0,1])\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label = 'loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim([0,1])\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and validation loss')\n",
        "plt.grid()"
      ]
    }
  ]
}
